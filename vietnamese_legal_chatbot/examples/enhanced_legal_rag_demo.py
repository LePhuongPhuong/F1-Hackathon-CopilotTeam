"""
Enhanced Vietnamese Legal RAG System Demo
With improved error handling and demo configuration
"""

import sys
import os
from datetime import datetime
from typing import Dict, List, Any

# Add project root to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.utils.demo_config import get_demo_config, validate_api_keys
from app.utils.api_key_manager import get_api_key_manager, setup_demo_keys
from app.models.legal_rag import (
    VietnameseLegalRAG,
    VietnameseLegalPromptTemplates,
    LegalCitationExtractor,
    VietnameseLegalValidator,
    LegalQueryResult,
    DocumentChunk
)


class MockPineconeService:
    """Mock Pinecone service for demo without real API calls"""
    
    def __init__(self):
        self.documents = []
        self.search_results = []
    
    def add_documents(self, documents: List[DocumentChunk]) -> bool:
        """Add documents to mock storage"""
        self.documents.extend(documents)
        print(f"ğŸ“š Added {len(documents)} documents to mock Pinecone")
        return True
    
    def search_similar(self, query: str, top_k: int = 5) -> List[DocumentChunk]:
        """Mock similarity search"""
        print(f"ğŸ” Mock search for: {query[:50]}...")
        
        # Return mock relevant documents based on keywords
        mock_docs = []
        
        if "dÃ¢n sá»±" in query.lower() or "civil" in query.lower():
            mock_docs.append(DocumentChunk(
                content="Luáº­t DÃ¢n sá»± 2015 quy Ä‘á»‹nh vá» quyá»n vÃ  nghÄ©a vá»¥ cá»§a cÃ´ng dÃ¢n. Äiá»u 15 quy Ä‘á»‹nh vá» quyá»n dÃ¢n sá»± Ä‘Æ°á»£c báº£o vá»‡ bá»Ÿi phÃ¡p luáº­t.",
                metadata={
                    "law_type": "Luáº­t",
                    "law_name": "Luáº­t DÃ¢n sá»±",
                    "year": "2015",
                    "article": "15",
                    "domain": "dan_su"
                },
                chunk_id="civil_law_001"
            ))
        
        if "lao Ä‘á»™ng" in query.lower() or "lÃ m viá»‡c" in query.lower():
            mock_docs.append(DocumentChunk(
                content="Bá»™ luáº­t Lao Ä‘á»™ng 2019 quy Ä‘á»‹nh thá»i gian lÃ m viá»‡c bÃ¬nh thÆ°á»ng khÃ´ng quÃ¡ 8 giá» má»™t ngÃ y vÃ  khÃ´ng quÃ¡ 48 giá» má»™t tuáº§n. Äiá»u 20 quy Ä‘á»‹nh cá»¥ thá»ƒ vá» thá»i gian lÃ m viá»‡c.",
                metadata={
                    "law_type": "Bá»™ luáº­t",
                    "law_name": "Bá»™ luáº­t Lao Ä‘á»™ng",
                    "year": "2019",
                    "article": "20",
                    "domain": "lao_dong"
                },
                chunk_id="labor_law_001"
            ))
        
        return mock_docs[:top_k]


class MockChatModel:
    """Mock chat model for demo without real API calls"""
    
    def __init__(self, config, api_key: str = None):
        self.config = config
        self.api_key = api_key or config.openai_chat_api_key
    
    def generate_response(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """Generate mock response based on the prompt"""
        user_message = messages[-1].get("content", "")
        
        # Extract query from the prompt
        if "Query:" in user_message:
            query_part = user_message.split("Query:")[1].split("\n")[0].strip()
        else:
            query_part = user_message[:100]
        
        # Generate contextual response based on keywords
        if "quyá»n dÃ¢n sá»±" in query_part.lower():
            return """Theo quy Ä‘á»‹nh táº¡i Luáº­t DÃ¢n sá»± sá»‘ 91/2015/QH13, quyá»n dÃ¢n sá»± cá»§a cÃ´ng dÃ¢n Ä‘Æ°á»£c báº£o vá»‡ toÃ n diá»‡n. Cá»¥ thá»ƒ:

1. **NguyÃªn táº¯c báº£o vá»‡**: Má»i quyá»n lá»£i há»£p phÃ¡p cá»§a cÃ´ng dÃ¢n Ä‘á»u Ä‘Æ°á»£c phÃ¡p luáº­t báº£o vá»‡
2. **Pháº¡m vi quyá»n dÃ¢n sá»±**: Bao gá»“m quyá»n vá» nhÃ¢n thÃ¢n, quyá»n tÃ i sáº£n, quyá»n sá»Ÿ há»¯u trÃ­ tuá»‡
3. **CÆ¡ cháº¿ thá»±c hiá»‡n**: ThÃ´ng qua há»‡ thá»‘ng tÃ²a Ã¡n vÃ  cÃ¡c cÆ¡ quan cÃ³ tháº©m quyá»n

**Tham chiáº¿u phÃ¡p lÃ½**: Äiá»u 15 Luáº­t DÃ¢n sá»± 2015."""
        
        elif "Ä‘iá»u 15" in query_part.lower():
            return """Äiá»u 15 Luáº­t DÃ¢n sá»± 2015 quy Ä‘á»‹nh vá» nguyÃªn táº¯c báº£o vá»‡ quyá»n dÃ¢n sá»±:

"Quyá»n dÃ¢n sá»± cá»§a cÃ´ng dÃ¢n, phÃ¡p nhÃ¢n Ä‘Æ°á»£c NhÃ  nÆ°á»›c thá»«a nháº­n, tÃ´n trá»ng, báº£o vá»‡ vÃ  báº£o Ä‘áº£m theo quy Ä‘á»‹nh cá»§a Luáº­t nÃ y vÃ  quy Ä‘á»‹nh khÃ¡c cá»§a phÃ¡p luáº­t cÃ³ liÃªn quan."

**Äiá»ƒm chÃ­nh**:
- NhÃ  nÆ°á»›c cÃ³ trÃ¡ch nhiá»‡m báº£o vá»‡ quyá»n dÃ¢n sá»±
- Quyá»n dÃ¢n sá»± Ä‘Æ°á»£c thá»«a nháº­n vÃ  tÃ´n trá»ng
- CÃ³ cÆ¡ cháº¿ báº£o Ä‘áº£m thá»±c hiá»‡n

**CÄƒn cá»© phÃ¡p luáº­t**: Luáº­t DÃ¢n sá»± sá»‘ 91/2015/QH13, cÃ³ hiá»‡u lá»±c tá»« 01/01/2017."""
        
        elif "thá»i gian lÃ m viá»‡c" in query_part.lower():
            return """Theo Bá»™ luáº­t Lao Ä‘á»™ng 2019, thá»i gian lÃ m viá»‡c Ä‘Æ°á»£c quy Ä‘á»‹nh nhÆ° sau:

**Thá»i gian lÃ m viá»‡c bÃ¬nh thÆ°á»ng**:
- KhÃ´ng quÃ¡ 8 giá» trong 1 ngÃ y lÃ m viá»‡c
- KhÃ´ng quÃ¡ 48 giá» trong 1 tuáº§n lÃ m viá»‡c

**Quy Ä‘á»‹nh Ä‘áº·c biá»‡t**:
- CÃ³ thá»ƒ lÃ m thÃªm giá» theo quy Ä‘á»‹nh
- Má»™t sá»‘ ngÃ nh nghá» cÃ³ quy Ä‘á»‹nh riÃªng
- Pháº£i Ä‘áº£m báº£o thá»i gian nghá»‰ ngÆ¡i

**CÄƒn cá»© phÃ¡p luáº­t**: Äiá»u 20 Bá»™ luáº­t Lao Ä‘á»™ng sá»‘ 45/2019/QH14."""
        
        elif "10 giá»" in query_part.lower() and "vi pháº¡m" in query_part.lower():
            return """**PHÃ‚N TÃCH TUÃ‚N THá»¦ PHÃP LUáº¬T**

YÃªu cáº§u lÃ m viá»‡c 10 giá»/ngÃ y cÃ³ thá»ƒ vi pháº¡m phÃ¡p luáº­t lao Ä‘á»™ng:

**Vi pháº¡m**: 
- VÆ°á»£t quÃ¡ giá»›i háº¡n 8 giá»/ngÃ y theo Äiá»u 20 Bá»™ luáº­t Lao Ä‘á»™ng 2019
- CÃ³ thá»ƒ Ä‘Æ°á»£c cháº¥p nháº­n náº¿u lÃ  lÃ m thÃªm giá» há»£p phÃ¡p

**Äiá»u kiá»‡n lÃ m thÃªm giá» há»£p phÃ¡p**:
- CÃ³ thá»a thuáº­n vá»›i ngÆ°á»i lao Ä‘á»™ng
- KhÃ´ng quÃ¡ 50% thá»i gian lÃ m viá»‡c bÃ¬nh thÆ°á»ng trong ngÃ y
- Äáº£m báº£o tráº£ lÆ°Æ¡ng lÃ m thÃªm giá» theo quy Ä‘á»‹nh

**Khuyáº¿n nghá»‹**: Cáº§n kiá»ƒm tra há»£p Ä‘á»“ng lao Ä‘á»™ng vÃ  thá»a thuáº­n vá» lÃ m thÃªm giá»."""
        
        else:
            return """Dá»±a trÃªn tÃ i liá»‡u phÃ¡p lÃ½ Ä‘Æ°á»£c cung cáº¥p, Ä‘Ã¢y lÃ  thÃ´ng tin tá»•ng há»£p vá» váº¥n Ä‘á» phÃ¡p lÃ½ báº¡n quan tÃ¢m.

Äá»ƒ cÃ³ Ä‘Æ°á»£c tÆ° váº¥n chÃ­nh xÃ¡c vÃ  phÃ¹ há»£p vá»›i tÃ¬nh huá»‘ng cá»¥ thá»ƒ, khuyáº¿n nghá»‹ báº¡n tham kháº£o Ã½ kiáº¿n cá»§a luáº­t sÆ° hoáº·c chuyÃªn gia phÃ¡p lÃ½ cÃ³ tháº©m quyá»n.

**LÆ°u Ã½**: ÄÃ¢y lÃ  thÃ´ng tin tham kháº£o, khÃ´ng thay tháº¿ cho tÆ° váº¥n phÃ¡p lÃ½ chuyÃªn nghiá»‡p."""


def run_enhanced_demo():
    """Run enhanced demo with better error handling"""
    
    print("ğŸ‡»ğŸ‡³ VIETNAMESE LEGAL AI CHATBOT SYSTEM")
    print("ğŸ›ï¸ Há»‡ thá»‘ng TÆ° váº¥n PhÃ¡p lÃ½ AI cho Viá»‡t Nam")
    print("=" * 60)
    print(f"ğŸ•’ Enhanced Demo started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # Load configuration and API key manager
    config = get_demo_config()
    api_manager = setup_demo_keys()
    
    print(f"ğŸ“‹ Configuration loaded: {config.chat_model}")
    print(f"ğŸ”‘ API Key Manager initialized in demo mode")
    
    # Get separate API configs
    chat_config = api_manager.get_chat_config()
    embedding_config = api_manager.get_embedding_config()
    
    # Check API configuration
    issues = validate_api_keys()
    if issues:
        print("\nâš ï¸ API Configuration Issues (using mock services):")
        for issue in issues:
            print(f"   â€¢ {issue}")
        print("   ğŸ“ Demo will run with mock services for demonstration")
        print(f"   ğŸ”‘ Chat Model: {chat_config['model']} with key {chat_config['api_key'][:10]}...")
        print(f"   ğŸ”‘ Embedding Model: {embedding_config['model']} with key {embedding_config['api_key'][:10]}...")
    
    print("\nğŸ”¥ === VIETNAMESE LEGAL RAG SYSTEM ENHANCED DEMO ===")
    print("ğŸ›ï¸  Há»‡ thá»‘ng TÆ° váº¥n PhÃ¡p lÃ½ AI cho Viá»‡t Nam")
    
    # Initialize with mock services
    try:
        print("\nğŸš€ Initializing Vietnamese Legal RAG System...")
        
        # Create mock services
        mock_pinecone = MockPineconeService()
        mock_chat = MockChatModel(config, chat_config['api_key'])
        
        # Initialize RAG system with separated API keys
        rag_system = VietnameseLegalRAG(
            pinecone_service=mock_pinecone,
            chat_model=mock_chat,
            embedding_api_key=embedding_config['api_key'],
            embedding_api_base=embedding_config['api_base']
        )
        
        print("âœ… RAG System initialized successfully with mock services!")
        
        # Demo queries with enhanced responses
        demo_queries = [
            {
                "question": "Quyá»n dÃ¢n sá»± cá»§a cÃ´ng dÃ¢n Ä‘Æ°á»£c báº£o vá»‡ nhÆ° tháº¿ nÃ o?",
                "category": "ğŸ” General Legal Query",
                "description": "Civil Rights Protection"
            },
            {
                "question": "Äiá»u 15 Luáº­t DÃ¢n sá»± quy Ä‘á»‹nh gÃ¬ vá» quyá»n dÃ¢n sá»±?",
                "category": "ğŸ“‹ Specific Law Query", 
                "description": "Article 15 Civil Code"
            },
            {
                "question": "Thá»i gian lÃ m viá»‡c theo quy Ä‘á»‹nh phÃ¡p luáº­t lÃ  bao lÃ¢u?",
                "category": "â° Procedure Query",
                "description": "Working Hours Regulation"
            },
            {
                "question": "CÃ´ng ty tÃ´i yÃªu cáº§u lÃ m viá»‡c 10 giá»/ngÃ y cÃ³ vi pháº¡m khÃ´ng?",
                "category": "âš–ï¸ Compliance Query",
                "description": "Working Hours Violation Check"
            }
        ]
        
        for i, query_info in enumerate(demo_queries, 1):
            print(f"\n{'=' * 60}")
            print(f"ğŸ“‹ QUERY {i}: {query_info['category']} - {query_info['description']}")
            print(f"â“ Question: {query_info['question']}")
            
            try:
                # Process query
                result = rag_system.query(query_info["question"])
                
                print(f"ğŸ·ï¸  Domain: {result.domain} | Type: {result.query_type}")
                print("-" * 60)
                
                # Display answer
                confidence_level = "HIGH" if result.confidence > 0.8 else "MEDIUM" if result.confidence > 0.5 else "LOW"
                print(f"ğŸ“ **ANSWER** (Confidence: {result.confidence:.2f} - {confidence_level}):\n")
                print(result.answer)
                
                # Show warnings if any
                if result.warnings:
                    print(f"\nâš ï¸ **WARNINGS**:")
                    for warning in result.warnings:
                        print(f"   â€¢ {warning}")
                
                # Show reasoning
                if result.reasoning:
                    reasoning_preview = result.reasoning[:100] + "..." if len(result.reasoning) > 100 else result.reasoning
                    print(f"\nğŸ§  **REASONING**: {reasoning_preview}")
                
            except Exception as e:
                print(f"âŒ Error processing query: {str(e)}")
        
        # Advanced features demo
        print(f"\n{'=' * 60}")
        print("ğŸ”¬ === ADVANCED FEATURES DEMO ===")
        
        # 1. Citation extraction
        print("\nğŸ”— 1. Citation Extraction Demo:")
        citation_extractor = LegalCitationExtractor()
        sample_text = """
        Theo Luáº­t DÃ¢n sá»± sá»‘ 91/2015/QH13, Nghá»‹ Ä‘á»‹nh sá»‘ 01/2021/NÄ-CP vÃ  Äiá»u 15 Khoáº£n 1,
        quyá»n dÃ¢n sá»± Ä‘Æ°á»£c báº£o vá»‡ toÃ n diá»‡n.
        """
        citations = citation_extractor.extract_citations_from_text(sample_text)
        print(f"ğŸ“‹ Extracted {len(citations)} citations from sample text:")
        for i, citation in enumerate(citations, 1):
            print(f"   {i}. {citation.full_reference}")
        
        # 2. Response validation
        print("\nâœ… 2. Response Validation Demo:")
        validator = VietnameseLegalValidator()
        sample_response = "Quyá»n dÃ¢n sá»± Ä‘Æ°á»£c báº£o vá»‡ theo phÃ¡p luáº­t Viá»‡t Nam."
        validation_result = validator.validate_response(sample_response, "dan_su")
        
        print(f"ğŸ¯ Validation Result: {'Valid' if validation_result.is_valid else 'Invalid'}")
        print(f"ğŸ“Š Confidence Adjustment: {validation_result.confidence_adjustment:+.2f}")
        if validation_result.warnings:
            print("âš ï¸ Warnings:")
            for warning in validation_result.warnings:
                print(f"   â€¢ {warning}")
        if validation_result.suggestions:
            print("ğŸ’¡ Suggestions:")
            for suggestion in validation_result.suggestions:
                print(f"   â€¢ {suggestion}")
        
        # 3. Prompt templates demo
        print("\nğŸ“ 3. Prompt Templates Demo:")
        templates = VietnameseLegalPromptTemplates()
        sample_query = "Quyá»n sá»Ÿ há»¯u nhÃ  Ä‘áº¥t nhÆ° tháº¿ nÃ o?"
        prompt = templates.get_general_prompt(sample_query, [], "dan_su")
        prompt_preview = prompt[:200] + "..." if len(prompt) > 200 else prompt
        print(f"ğŸ¯ Generated prompt preview: {prompt_preview}")
        
        # Demo summary
        print(f"\n{'=' * 60}")
        print("ğŸ‰ === ENHANCED DEMO SUMMARY ===")
        print("âœ… Vietnamese Legal RAG System successfully demonstrated!")
        print("ğŸš€ Features showcased:")
        print("   â€¢ Enhanced error handling and mock services")
        print("   â€¢ Vietnamese legal citation extraction")
        print("   â€¢ Response validation and quality assurance")
        print("   â€¢ Multiple legal domains support")
        print("   â€¢ Prompt template system")
        print("   â€¢ Configuration management")
        print("   â€¢ Robust fallback mechanisms")
        
        print(f"\nğŸ“Š Total Demo Queries: {len(demo_queries)}")
        print("ğŸ† System ready for integration with real services!")
        
    except Exception as e:
        print(f"âŒ Demo initialization failed: {str(e)}")
        print("ğŸ’¡ Please check configuration and dependencies")


if __name__ == "__main__":
    run_enhanced_demo()
