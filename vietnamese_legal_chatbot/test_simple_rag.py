"""
Simple Vietnamese Legal RAG Demo
With working text-embedding-3-small configuration
"""

import os
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv()

def test_simple_rag():
    """Test simple RAG functionality with actual API"""
    
    print("ğŸ‡»ğŸ‡³ VIETNAMESE LEGAL AI - SIMPLE RAG TEST")
    print("=" * 60)
    print(f"ğŸ•’ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # Load settings
    embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
    chat_model = os.getenv("CHAT_MODEL", "gpt-4o-mini")
    
    print(f"ï¿½ Using embedding model: {embedding_model}")
    print(f"ğŸ¤– Using chat model: {chat_model}")
    
    # Get API keys
    chat_api_key = os.getenv("OPENAI_API_KEY")
    embedding_api_key = os.getenv("OPENAI_EMBEDDING_API_KEY")
    chat_api_base = os.getenv("OPENAI_API_BASE")
    embedding_api_base = os.getenv("OPENAI_EMBEDDING_API_BASE")
    
    print(f"ğŸ”‘ Chat API Key: {chat_api_key[:8]}..." if chat_api_key else "âŒ No chat API key")
    print(f"ğŸ”‘ Embedding API Key: {embedding_api_key[:8]}..." if embedding_api_key else "âŒ No embedding API key")
    
    # Test queries
    test_queries = [
        "Quyá»n dÃ¢n sá»± cá»§a cÃ´ng dÃ¢n Ä‘Æ°á»£c báº£o vá»‡ nhÆ° tháº¿ nÃ o?",
        "Thá»i gian lÃ m viá»‡c theo quy Ä‘á»‹nh phÃ¡p luáº­t lÃ  bao lÃ¢u?"
    ]
    
    # Mock legal documents (Vietnamese legal content)
    mock_docs = [
        {
            "content": "Luáº­t DÃ¢n sá»± 2015 quy Ä‘á»‹nh vá» quyá»n vÃ  nghÄ©a vá»¥ cá»§a cÃ´ng dÃ¢n. Äiá»u 15 quy Ä‘á»‹nh quyá»n dÃ¢n sá»± Ä‘Æ°á»£c báº£o vá»‡ bá»Ÿi phÃ¡p luáº­t. NhÃ  nÆ°á»›c cÃ³ trÃ¡ch nhiá»‡m thá»«a nháº­n, tÃ´n trá»ng vÃ  báº£o vá»‡ quyá»n dÃ¢n sá»± cá»§a cÃ´ng dÃ¢n.",
            "metadata": {"law": "Luáº­t DÃ¢n sá»± 2015", "article": "Äiá»u 15"}
        },
        {
            "content": "Bá»™ luáº­t Lao Ä‘á»™ng 2019 quy Ä‘á»‹nh thá»i gian lÃ m viá»‡c khÃ´ng quÃ¡ 8 giá» trong 1 ngÃ y vÃ  khÃ´ng quÃ¡ 48 giá» trong 1 tuáº§n. NgÆ°á»i lao Ä‘á»™ng cÃ³ quyá»n nghá»‰ ngÆ¡i vÃ  Ä‘Æ°á»£c tráº£ lÆ°Æ¡ng khi lÃ m thÃªm giá».",
            "metadata": {"law": "Bá»™ luáº­t Lao Ä‘á»™ng 2019", "article": "Äiá»u 20"}
        }
    ]
    
    try:
        # Create OpenAI clients
        embedding_client = OpenAI(
            api_key=embedding_api_key,
            base_url=embedding_api_base
        )
        
        chat_client = OpenAI(
            api_key=chat_api_key,
            base_url=chat_api_base
        )
        
        print("âœ… OpenAI clients created successfully")
        
        # Process each query
        for i, query in enumerate(test_queries, 1):
            print(f"\n{'='*60}")
            print(f"ğŸ“‹ QUERY {i}: {query}")
            print(f"{'='*60}")
            
            # Step 1: Create query embedding
            print("ğŸ” Step 1: Creating query embedding...")
            query_response = embedding_client.embeddings.create(
                model=embedding_model,
                input=query
            )
            query_embedding = query_response.data[0].embedding
            print(f"âœ… Query embedding created (dimension: {len(query_embedding)})")
            
            # Step 2: Create document embeddings and find similarity
            print("ğŸ“š Step 2: Processing documents...")
            best_doc = None
            best_similarity = -1
            
            for doc in mock_docs:
                doc_response = embedding_client.embeddings.create(
                    model=embedding_model,
                    input=doc["content"]
                )
                doc_embedding = doc_response.data[0].embedding
                
                # Simple cosine similarity
                dot_product = sum(a * b for a, b in zip(query_embedding, doc_embedding))
                similarity = dot_product / (sum(a*a for a in query_embedding)**0.5 * sum(b*b for b in doc_embedding)**0.5)
                
                print(f"ğŸ“„ Document similarity: {similarity:.3f} - {doc['metadata']['law']}")
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_doc = doc
            
            print(f"ğŸ¯ Best match: {best_doc['metadata']['law']} (similarity: {best_similarity:.3f})")
            
            # Step 3: Generate response
            print("ğŸ’¬ Step 3: Generating response...")
            prompt = f"""Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n phÃ¡p lÃ½ Viá»‡t Nam. Dá»±a trÃªn tÃ i liá»‡u phÃ¡p lÃ½ sau Ä‘Ã¢y, hÃ£y tráº£ lá»i cÃ¢u há»i má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  há»¯u Ã­ch.

TÃ i liá»‡u tham kháº£o:
{best_doc['content']}

CÃ¢u há»i: {query}

Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n vÃ  chÃ­nh xÃ¡c:"""

            chat_response = chat_client.chat.completions.create(
                model=chat_model,
                messages=[
                    {"role": "system", "content": "Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n phÃ¡p lÃ½ Viá»‡t Nam."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.1
            )
            
            answer = chat_response.choices[0].message.content
            
            # Display results
            print("\nğŸ‰ RESULT:")
            print("-" * 50)
            print(f"â“ CÃ¢u há»i: {query}")
            print(f"ğŸ“š TÃ i liá»‡u: {best_doc['metadata']['law']} - {best_doc['metadata']['article']}")
            print(f"ğŸ’¡ Tráº£ lá»i:\n{answer}")
            print("-" * 50)
        
        print(f"\n{'='*60}")
        print("ğŸ‰ Simple RAG test completed successfully!")
        print("âœ… All components working: Embedding âœ“ Chat âœ“ RAG Pipeline âœ“")
        print(f"ğŸ” Embedding Model: {embedding_model}")
        print(f"ğŸ’¬ Chat Model: {chat_model}")
        print(f"{'='*60}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error in RAG test: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_simple_rag()
