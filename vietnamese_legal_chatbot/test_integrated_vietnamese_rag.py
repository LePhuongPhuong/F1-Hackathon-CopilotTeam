"""
Integrated Test: Vietnamese Text Processing with RAG System
Test xá»­ lÃ½ vÄƒn báº£n tiáº¿ng Viá»‡t tÃ­ch há»£p vá»›i há»‡ thá»‘ng RAG
"""

import os
import sys
from datetime import datetime
from dotenv import load_dotenv

# Add project root to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Load environment variables
load_dotenv()

from openai import OpenAI
from app.utils.text_processing import (
    process_vietnamese_legal_text, 
    preprocess_vietnamese_query,
    get_legal_domain,
    extract_legal_citations
)

def test_integrated_vietnamese_rag():
    """Test Vietnamese text processing integrated with RAG"""
    
    print("ğŸ‡»ğŸ‡³ INTEGRATED VIETNAMESE RAG TEST")
    print("=" * 60)
    print(f"ğŸ•’ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # Test queries with different intents and domains
    test_queries = [
        {
            "query": "Quyá»n dÃ¢n sá»± cá»§a cÃ´ng dÃ¢n Ä‘Æ°á»£c báº£o vá»‡ nhÆ° tháº¿ nÃ o theo Äiá»u 15 Bá»™ luáº­t DÃ¢n sá»± 2015?",
            "expected_domain": "dan_su",
            "expected_intent": "rights_inquiry"
        },
        {
            "query": "Thá»§ tá»¥c Ä‘Äƒng kÃ½ káº¿t hÃ´n cáº§n nhá»¯ng giáº¥y tá» gÃ¬?",
            "expected_domain": "hanh_chinh", 
            "expected_intent": "procedure_inquiry"
        },
        {
            "query": "CÃ´ng ty báº¯t nhÃ¢n viÃªn lÃ m thÃªm giá» 12 tiáº¿ng/ngÃ y cÃ³ vi pháº¡m Bá»™ luáº­t Lao Ä‘á»™ng khÃ´ng?",
            "expected_domain": "lao_dong",
            "expected_intent": "violation_inquiry"
        },
        {
            "query": "Há»£p Ä‘á»“ng mua bÃ¡n báº¥t Ä‘á»™ng sáº£n cáº§n cÃ³ nhá»¯ng Ä‘iá»u khoáº£n báº¯t buá»™c nÃ o?",
            "expected_domain": "thuong_mai",
            "expected_intent": "information_inquiry"
        }
    ]
    
    # Mock legal documents with enhanced Vietnamese content
    mock_documents = [
        {
            "content": "Äiá»u 15 Bá»™ luáº­t DÃ¢n sá»± 2015 quy Ä‘á»‹nh: Quyá»n dÃ¢n sá»± cá»§a cÃ´ng dÃ¢n, phÃ¡p nhÃ¢n Ä‘Æ°á»£c NhÃ  nÆ°á»›c thá»«a nháº­n, tÃ´n trá»ng, báº£o vá»‡ vÃ  báº£o Ä‘áº£m theo quy Ä‘á»‹nh cá»§a Luáº­t nÃ y vÃ  quy Ä‘á»‹nh khÃ¡c cá»§a phÃ¡p luáº­t cÃ³ liÃªn quan. Viá»‡c thá»±c hiá»‡n quyá»n dÃ¢n sá»± khÃ´ng Ä‘Æ°á»£c xÃ¢m pháº¡m quyá»n vÃ  lá»£i Ã­ch há»£p phÃ¡p cá»§a ngÆ°á»i khÃ¡c, khÃ´ng trÃ¡i Ä‘áº¡o Ä‘á»©c xÃ£ há»™i.",
            "metadata": {"law": "Bá»™ luáº­t DÃ¢n sá»± 2015", "article": "Äiá»u 15", "domain": "dan_su"}
        },
        {
            "content": "Äiá»u 104 Bá»™ luáº­t Lao Ä‘á»™ng 2019 quy Ä‘á»‹nh thá»i gian lÃ m viá»‡c bÃ¬nh thÆ°á»ng khÃ´ng quÃ¡ 8 giá» trong 1 ngÃ y vÃ  khÃ´ng quÃ¡ 48 giá» trong 1 tuáº§n. NgÆ°á»i sá»­ dá»¥ng lao Ä‘á»™ng cÃ³ thá»ƒ Ã¡p dá»¥ng cháº¿ Ä‘á»™ lÃ m viá»‡c theo ca, lÃ m viá»‡c ban Ä‘Ãªm Ä‘á»‘i vá»›i cÃ¡c cÃ´ng viá»‡c thÃ­ch há»£p.",
            "metadata": {"law": "Bá»™ luáº­t Lao Ä‘á»™ng 2019", "article": "Äiá»u 104", "domain": "lao_dong"}
        },
        {
            "content": "Thá»§ tá»¥c Ä‘Äƒng kÃ½ káº¿t hÃ´n theo Luáº­t HÃ´n nhÃ¢n vÃ  Gia Ä‘Ã¬nh 2014 yÃªu cáº§u: ÄÆ¡n Ä‘Äƒng kÃ½ káº¿t hÃ´n, Chá»©ng minh nhÃ¢n dÃ¢n/CÄƒn cÆ°á»›c cÃ´ng dÃ¢n, Giáº¥y khai sinh, Giáº¥y chá»©ng nháº­n tÃ¬nh tráº¡ng hÃ´n nhÃ¢n (náº¿u cÃ³), Giáº¥y khÃ¡m sá»©c khá»e tiá»n hÃ´n nhÃ¢n.",
            "metadata": {"law": "Luáº­t HÃ´n nhÃ¢n vÃ  Gia Ä‘Ã¬nh 2014", "procedure": "Ä‘Äƒng kÃ½ káº¿t hÃ´n", "domain": "hanh_chinh"}
        }
    ]
    
    # Get API configuration
    embedding_api_key = os.getenv("OPENAI_EMBEDDING_API_KEY")
    embedding_api_base = os.getenv("OPENAI_EMBEDDING_API_BASE")
    chat_api_key = os.getenv("OPENAI_API_KEY")
    chat_api_base = os.getenv("OPENAI_API_BASE")
    
    try:
        # Create OpenAI clients
        embedding_client = OpenAI(
            api_key=embedding_api_key,
            base_url=embedding_api_base
        )
        
        chat_client = OpenAI(
            api_key=chat_api_key,
            base_url=chat_api_base
        )
        
        print("âœ… OpenAI clients initialized")
        
        # Process each test query
        for i, test_case in enumerate(test_queries, 1):
            query = test_case["query"]
            
            print(f"\n{'='*60}")
            print(f"ğŸ“‹ TEST CASE {i}")
            print(f"â“ Query: {query}")
            print(f"{'='*60}")
            
            # Step 1: Vietnamese text processing
            print("ğŸ” Step 1: Vietnamese Text Processing")
            query_analysis = preprocess_vietnamese_query(query)
            domain = get_legal_domain(query)
            citations = extract_legal_citations(query)
            
            print(f"   âœ… Intent: {query_analysis['intent']}")
            print(f"   âœ… Domain: {domain}")
            print(f"   âœ… Legal terms: {query_analysis['legal_terms']}")
            print(f"   âœ… Search keywords: {query_analysis['search_keywords'][:5]}")
            if citations:
                print(f"   âœ… Citations: {[c['full_text'] for c in citations]}")
            
            # Verify expectations
            expected_domain = test_case["expected_domain"]
            expected_intent = test_case["expected_intent"]
            
            domain_match = "âœ…" if domain == expected_domain else "âŒ"
            intent_match = "âœ…" if query_analysis['intent'] == expected_intent else "âŒ"
            
            print(f"   {domain_match} Domain prediction: {domain} (expected: {expected_domain})")
            print(f"   {intent_match} Intent prediction: {query_analysis['intent']} (expected: {expected_intent})")
            
            # Step 2: Document retrieval with enhanced processing
            print("ğŸ“š Step 2: Enhanced Document Retrieval")
            query_embedding = embedding_client.embeddings.create(
                model="text-embedding-3-small",
                input=query_analysis['normalized_query']
            ).data[0].embedding
            
            best_doc = None
            best_similarity = -1
            
            for doc in mock_documents:
                # Process document content
                doc_analysis = process_vietnamese_legal_text(doc["content"])
                
                # Create document embedding
                doc_embedding = embedding_client.embeddings.create(
                    model="text-embedding-3-small",
                    input=doc_analysis.normalized_text
                ).data[0].embedding
                
                # Calculate similarity
                dot_product = sum(a * b for a, b in zip(query_embedding, doc_embedding))
                similarity = dot_product / (sum(a*a for a in query_embedding)**0.5 * sum(b*b for b in doc_embedding)**0.5)
                
                # Domain boost
                if doc["metadata"].get("domain") == domain:
                    similarity += 0.1  # Boost for matching domain
                
                print(f"   ğŸ“„ {doc['metadata']['law']}: similarity={similarity:.3f}")
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_doc = doc
            
            print(f"   ğŸ¯ Best match: {best_doc['metadata']['law']} (similarity: {best_similarity:.3f})")
            
            # Step 3: Enhanced response generation
            print("ğŸ’¬ Step 3: Enhanced Response Generation")
            
            # Create enhanced prompt with Vietnamese context
            enhanced_prompt = f"""Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n phÃ¡p lÃ½ Viá»‡t Nam vá»›i chuyÃªn mÃ´n sÃ¢u vá» {domain}.

Dá»±a trÃªn tÃ i liá»‡u phÃ¡p lÃ½ sau Ä‘Ã¢y:
{best_doc['content']}

CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {query}
Intent Ä‘Æ°á»£c phÃ¡t hiá»‡n: {query_analysis['intent']}
Thuáº­t ngá»¯ phÃ¡p lÃ½ liÃªn quan: {', '.join(query_analysis['legal_terms'])}

HÃ£y tráº£ lá»i má»™t cÃ¡ch:
- ChÃ­nh xÃ¡c vÃ  dá»±a trÃªn vÄƒn báº£n phÃ¡p luáº­t
- Dá»… hiá»ƒu cho ngÆ°á»i dÃ¢n
- CÃ³ trÃ­ch dáº«n cá»¥ thá»ƒ Ä‘iá»u khoáº£n phÃ¡p luáº­t
- PhÃ¹ há»£p vá»›i ngá»¯ cáº£nh Viá»‡t Nam

Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t:"""

            response = chat_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n phÃ¡p lÃ½ Viá»‡t Nam cÃ³ kinh nghiá»‡m vÃ  uy tÃ­n."},
                    {"role": "user", "content": enhanced_prompt}
                ],
                max_tokens=600,
                temperature=0.1
            )
            
            answer = response.choices[0].message.content
            
            # Display final result
            print("\nğŸ‰ ENHANCED RESULT:")
            print("-" * 50)
            print(f"â“ CÃ¢u há»i: {query}")
            print(f"ğŸ·ï¸ LÄ©nh vá»±c: {domain}")
            print(f"ğŸ¯ Ã Ä‘á»‹nh: {query_analysis['intent']}")
            print(f"ğŸ“š TÃ i liá»‡u: {best_doc['metadata']['law']}")
            print(f"ğŸ’¡ Tráº£ lá»i:\n{answer}")
            print("-" * 50)
        
        print(f"\n{'='*60}")
        print("ğŸ‰ Integrated Vietnamese RAG test completed successfully!")
        print("âœ… Text Processing âœ“ Domain Detection âœ“ Intent Recognition âœ“")
        print("âœ… Legal Term Extraction âœ“ Citation Parsing âœ“ Enhanced RAG âœ“")
        print(f"{'='*60}")
        
    except Exception as e:
        print(f"âŒ Error in integrated test: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_integrated_vietnamese_rag()
